<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>机器学习实战第一课——KNN近邻算法</title>
      <link href="/2020/01/16/ji-qi-xue-xi-shi-zhan-di-yi-ke-knn-jin-lin-suan-fa/"/>
      <url>/2020/01/16/ji-qi-xue-xi-shi-zhan-di-yi-ke-knn-jin-lin-suan-fa/</url>
      
        <content type="html"><![CDATA[<blockquote><h2 id="纸上得来终觉浅，绝知此事要躬行"><a href="#纸上得来终觉浅，绝知此事要躬行" class="headerlink" title="纸上得来终觉浅，绝知此事要躬行"></a><strong>纸上得来终觉浅，绝知此事要躬行</strong></h2></blockquote><p>　　距离我“入门”机器已经半年了，之所以是假入门，是因为平时课程实在是太繁重了，刷均分，赶作业，完全顾不上认真学习。因为渐渐的觉得每周跟的组会上面研究生学长分享的那些东西听不太懂，是为基础过于薄弱，同时又进入了一个数据挖掘的课题组，不能当个半吊子(知识点懂一半，代码不会写)啥都不懂，所以打算趁着寒假时间还算充足，把《机器学习实战》上的算法都实现一遍（主要代码与内容学习还是参考apachecn的github所得）。<br>　　今天复现的是K-近邻算法，是所有机器学习算法中最简单的之一[wiki]，主要思想是求出测试数据与全体训练数据集之间的欧氏距离，然后对欧氏距离进行排序，返回前k个距离最短的样本数据集，这k个数据项中出现次数最多的标签即为测试数据的预测标签。为防止各种标签在k个最短距离数据项中只出现一次，k应该大于标签类别数（我瞎猜的，应该是这样）<br>　　我的python基本上处于一个入门阶段，今天实操一遍，收获颇丰，也深感能力之不足，同志仍需努力。<br>　　KNN没有训练过程，只有一次一次的计算与比较，所以说它的空间复杂度与计算复杂度都很高，下面是用python复现的代码<br>总的代码如下</p><h3 id="1-准备模块"><a href="#1-准备模块" class="headerlink" title="1. 准备模块"></a>1. 准备模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><ul><li>__future__模块可以引用未来版本python库中的函数，其实我的版本已经是3.x，所以没有必要走这一步</li><li>将numpy导入有多种方法，一般常用import numpy as np，这里的这种方法可以不加前缀直接调用numpy中的函数如zeros，这种方式类似于C语言中的名称空间<h3 id="2-数据读取模块"><a href="#2-数据读取模块" class="headerlink" title="2.数据读取模块"></a>2.数据读取模块</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">fr&#x3D;open(&quot;E:\MachineLearning\KNN\dataset\datingTestSet2.txt&quot;)</span><br><span class="line">numberOfLines&#x3D;len(fr.readlines())</span><br><span class="line">fr.seek(0)</span><br><span class="line">returnMat&#x3D;zeros((numberOfLines,3))</span><br><span class="line">classLabelVector&#x3D;[]</span><br><span class="line">index&#x3D;0</span><br><span class="line">for line in fr.readlines():</span><br><span class="line">    line&#x3D;line.strip()</span><br><span class="line">    listFromLine&#x3D;line.split(&#39;\t&#39;)</span><br><span class="line">    returnMat[index,:]&#x3D;listFromLine[0:3]</span><br><span class="line">    classLabelVector.append(int(listFromLine[-1]))  # classLabelVector 与 returnMat 一一对应，前者为所属标签，后者为具体数据</span><br><span class="line">    index+&#x3D;1</span><br></pre></td></tr></table></figure></li><li>这一部分呢，强调一下文件的读取，如今数据挖掘与数据分析方面更常用pandas，不过目前还不需要那么高深的功能，以后再用。</li><li>readlines()会按行读取数据（读取所有行并返回list），读取完毕之后指向最后一个字符，所以如果需要重新读取，要用seek(0)指向初始位置<br>接下来strip()函数可以删去str的头或尾的换行符或者空格或者，指定字符（需指明参数）</li><li>split()函数指定分隔符对str进行切片，在本代码中将str分成四个list，前三个为数据，存入returnMat中，最后一个是标签，用append()方法存入classLabelVector中</li><li>returnMat的数据结构为array，矩阵结构在存入数据时可以利用index索引，了解的不是很全，目前只知道这一个用法，以后再分析<h3 id="3-可视化模块"><a href="#3-可视化模块" class="headerlink" title="3.可视化模块"></a>3.可视化模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">labels=classLabelVector</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>), dpi=<span class="number">80</span>)</span><br><span class="line">axes = plt.subplot(<span class="number">111</span>)</span><br><span class="line"><span class="comment"># 将三类数据分别取出来</span></span><br><span class="line"><span class="comment"># x轴代表飞行的里程数</span></span><br><span class="line"><span class="comment"># y轴代表玩视频游戏的百分比</span></span><br><span class="line">type1_x = []</span><br><span class="line">type1_y = []</span><br><span class="line">type2_x = []</span><br><span class="line">type2_y = []</span><br><span class="line">type3_x = []</span><br><span class="line">type3_y = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(labels)):</span><br><span class="line">    <span class="keyword">if</span> labels[i] == <span class="number">1</span>:  <span class="comment"># 不喜欢</span></span><br><span class="line">        type1_x.append(returnMat[i][<span class="number">0</span>])</span><br><span class="line">        type1_y.append(returnMat[i][<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> labels[i] == <span class="number">2</span>:  <span class="comment"># 魅力一般</span></span><br><span class="line">        type2_x.append(returnMat[i][<span class="number">0</span>])</span><br><span class="line">        type2_y.append(returnMat[i][<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> labels[i] == <span class="number">3</span>:  <span class="comment"># 极具魅力</span></span><br><span class="line">        type3_x.append(returnMat[i][<span class="number">0</span>])</span><br><span class="line">        type3_y.append(returnMat[i][<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">type1 = axes.scatter(type1_x, type1_y, s=<span class="number">20</span>, c=<span class="string">'red'</span>)</span><br><span class="line">type2 = axes.scatter(type2_x, type2_y, s=<span class="number">40</span>, c=<span class="string">'green'</span>)</span><br><span class="line">type3 = axes.scatter(type3_x, type3_y, s=<span class="number">50</span>, c=<span class="string">'blue'</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">'Miles earned per year'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Percentage of events spent playing video games'</span>)</span><br><span class="line">axes.legend((type1, type2, type3), (<span class="string">u'dislike'</span>, <span class="string">u'Charismatic'</span>, <span class="string">u'Very attractive'</span>), loc=<span class="number">2</span>,)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>为了让画出来的图好看，指定不同标签不同颜色，所以画点的时候分三次，得到的图如下所示<img src="https://img2018.cnblogs.com/common/1675876/202001/1675876-20200112001536955-2127082585.png" alt="可视化"><h3 id="4-归一化"><a href="#4-归一化" class="headerlink" title="4.归一化"></a>4.归一化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">normMat=zeros((numberOfLines,<span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]:</span><br><span class="line">    max=returnMat[:,i].max()</span><br><span class="line">    min=returnMat[:,i].min()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        normMat[j,i]=(returnMat[j,i]-min)/(max-min)</span><br><span class="line"><span class="comment"># done</span></span><br></pre></td></tr></table></figure>归一化是将所有数据都映射到一个固定的区间之中，上述方法是在[0,1]区间之间，这么做的目的是使各类数据的权重保持一致，保证某一类数据的影响不会强于其他<br><strong>常见归一化方法有:</strong></li><li>线性转换： newValue=(oldValue-min)/(max-min) max和min为该组数据集中的最大最小特征值</li><li>对数转换： y=log10(x)</li><li>反余切转换：y=arctan(x)*2/PI<h3 id="5-KNN算法部分"><a href="#5-KNN算法部分" class="headerlink" title="5.KNN算法部分"></a>5.KNN算法部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">inx=[<span class="number">0.40166314</span>, <span class="number">0.56719748</span>, <span class="number">0.52034602</span>] <span class="comment"># 作为输入的样本</span></span><br><span class="line">dataSetSize=normMat.shape[<span class="number">0</span>]</span><br><span class="line">diffMat = tile(inx, (dataSetSize,<span class="number">1</span>))-normMat</span><br><span class="line">sqDiffMat = diffMat**<span class="number">2</span></span><br><span class="line">distances=(sqDiffMat.sum(axis=<span class="number">1</span>))**<span class="number">0.5</span></span><br><span class="line">sortedDistIndicies = distances.argsort() <span class="comment"># argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引号)，所以并不会影响对应的label的值</span></span><br><span class="line"><span class="comment"># k取5</span></span><br><span class="line">classCount=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    voteIlabel = labels[sortedDistIndicies[i]]</span><br><span class="line">    classCount[voteIlabel] = classCount.get(voteIlabel,<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>其实到了这一部分发现难度反而没有前面的高，可能是因为这个算法比较简单<br><strong>值得注意的点有:</strong></li><li>tile()函数用来对数组进行复制第二个参数(x,y)分别表示行复制多少次，列复制多少次</li><li>argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引号)，所以并不会影响对应的label的值</li><li>classCount是一个构造字典的过程，对字典还不太熟，但今天的一天的已经结束了，没精力再去深究了，不干了，睡大觉<br><strong>第一天的工作，over！</strong></li></ul><hr><p>DAY 2 对KNN算法进行一个总结（来自apachecn上的小结，在此做一个备份）：<br><strong>近似误差与估计误差</strong></p><ul><li>近似误差：可以理解为对现有训练集的训练误差。</li><li>估计误差：可以理解为对测试集的测试误差。</li></ul><p>近似误差关注训练集，如果近似误差小了会出现过拟合的现象，对现有的训练集能有很好的预测，但是对未知的测试样本将会出现较大偏差的预测。模型本身不是最接近最佳模型。</p><p>估计误差关注测试集，估计误差小了说明对未知数据的预测能力好。模型本身最接近最佳模型。</p><p>推荐使用交叉验证<a href="https://zhuanlan.zhihu.com/p/24825503" target="_blank" rel="noopener">[知乎]</a><a href="https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89" target="_blank" rel="noopener">[wiki]</a><a href="https://blog.csdn.net/lhx878619717/article/details/49079785" target="_blank" rel="noopener">[CSDN]</a>选取合适的k值（交叉验证是一种评估统计分析、机器学习算法对独立于训练数据的数据集的泛化能力）</p><p><strong>距离度量 Metric/Distance Measure</strong></p><p>度量距离除了本文中用的欧氏距离之外，还可以是Minkowski距离或者曼哈顿距离（更多细节可以参看 sklearn 中 valid_metric 部分）</p><p><strong>算法</strong><br>算法：（sklearn 上有三种）</p><ul><li>Brute Force 暴力计算/线性扫描（数据结构中学过的BF算法，暴力模式匹配）</li><li>KD Tree 使用二叉树根据数据维度来平分参数空间<a href="https://www.cnblogs.com/eyeszjwang/articles/2429382.html" target="_blank" rel="noopener">[博客园]</a>。对高维数据处理时经常会用到</li><li>Ball Tree 使用一系列的超球体来平分训练数据集。（Ball Tree了解的不是很多）</li></ul><p><font color=red><strong>最后，在这里附上apachecn/AiLearning的<a href="https://github.com/apachecn/AiLearning" target="_blank" rel="noopener">github</a>，里面有非常丰富的AI领域学习资料，收获颇丰，十分感谢</strong></font></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>新的博客地址</title>
      <link href="/2020/01/16/xin-de-bo-ke-di-zhi/"/>
      <url>/2020/01/16/xin-de-bo-ke-di-zhi/</url>
      
        <content type="html"><![CDATA[<p>哈，github运行网页实在是太慢了，现在在码云上也开了个仓库（gitee pages），网址如下<br><a href="http://xiuzhedorothy.gitee.io/" target="_blank" rel="noopener">点击这里</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 博客运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/01/15/hello-world/"/>
      <url>/2020/01/15/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
